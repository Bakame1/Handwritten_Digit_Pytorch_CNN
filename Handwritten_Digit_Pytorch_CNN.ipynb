{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGwWn4E7RCWi8Gb+Q1cwGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bakame1/Handwritten_Digit_Pytorch_CNN/blob/main/Handwritten_Digit_Pytorch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VP3nvCbmmpSs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn                     # Pour construire les couches du réseau de neurones\n",
        "import torch.optim as optim               # Pour les optimiseurs (ex: Adam)\n",
        "import torch.nn.functional as F           # Pour les fonctions d'activation (ex: ReLU)\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms # Pour transformer les données (ex: image en Tenseur)\n",
        "from torch.utils.data import DataLoader   # Pour charger les données par lots (batches)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Préparer les données (MNIST)"
      ],
      "metadata": {
        "id": "aLodOkolps4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation : Convertir les images en Tenseurs PyTorch\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Télécharger le jeu de données d'entraînement\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "# Créer un chargeur de données pour l'entraînement (par lots de 64)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Télécharger le jeu de données de test\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                     download=True, transform=transform)\n",
        "# Créer un chargeur de données pour le test\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgCqvbEPmvN3",
        "outputId": "459070db-3d37-4b92-f446-1cb52d2cf181"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.08MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.65MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.49MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Définir le petit CNN"
      ],
      "metadata": {
        "id": "J5ehHwn3pza9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # 1. Couche de convolution :\n",
        "        #Prend 1 canal d'entrée (image en noir et blanc)\n",
        "        #Produit 10 canaux de sortie (10 \"filtres\")\n",
        "        #Taille du noyau (filtre) = 5x5\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
        "\n",
        "        # 2. Couche de Max Pooling :\n",
        "        #    Réduit la taille de l'image (par 2) pour garder l'essentiel\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 3. Couche linéaire (entièrement connectée) :\n",
        "        #Les images (après conv + pool) sont \"aplaties\" (flatten)\n",
        "        #La taille d'entrée est 10 (canaux) * 12 * 12 (taille de l'image réduite)\n",
        "        #La taille de sortie est 10, car nous avons 10 classes (chiffres 0-9)\n",
        "        self.fc1 = nn.Linear(in_features=10 * 12 * 12, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Définit comment les données passent à travers les couches\n",
        "\n",
        "        #Applique Conv1, puis ReLU (activation), puis Pooling\n",
        "        #x shape: [64, 1, 28, 28] (batch, canal, hauteur, largeur)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #x shape: [64, 10, 12, 12]\n",
        "\n",
        "        #Aplatir le tenseur pour la couche linéaire\n",
        "        #-1 signifie \"calcule la taille de cette dimension automatiquement\"\n",
        "        x = torch.flatten(x, 1) # Aplatit tout sauf la dimension 0 (le batch)\n",
        "        #x shape: [64, 1440] (où 1440 = 10*12*12)\n",
        "\n",
        "        # Appliquer la couche linéaire\n",
        "        x = self.fc1(x)\n",
        "        # x shape: [64, 10]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "-b--ud8Amyyy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entraîner le modèle"
      ],
      "metadata": {
        "id": "0Ylz-Th8qTks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer une instance de notre modèle\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Définir la fonction de perte (Loss)\n",
        "# On choisit CrossEntropyLoss car c'est un standard pour la classification.\n",
        "# Elle combine Softmax et la perte.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Définir l'optimiseur (comment le modèle apprend)\n",
        "# On teste avec Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Début de l'entraînement...\")\n",
        "num_epochs = 3 #On fait 3 passages complets sur les données\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # 1. Obtenir les données : un lot (batch) d'images et leurs étiquettes\n",
        "        inputs, labels = data\n",
        "\n",
        "        # 2. Zéro-iser les gradients (important avant chaque backpropagation)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. Forward pass : passer les images dans le modèle\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 4. Calculer la perte (loss)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 5. Backward pass : calculer les gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # 6. Mettre à jour les poids du modèle\n",
        "        optimizer.step()\n",
        "\n",
        "        # Afficher les statistiques\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # Afficher toutes les 200 mini-batches\n",
        "            print(f'[Époque {epoch + 1}, Batch {i + 1}] perte: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Entraînement terminé.')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZdXfJEvm2G1",
        "outputId": "f279ed20-8cfd-4501-88cd-1d99203fd122"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Début de l'entraînement...\n",
            "[Époque 1, Batch 200] perte: 0.688\n",
            "[Époque 1, Batch 400] perte: 0.290\n",
            "[Époque 1, Batch 600] perte: 0.222\n",
            "[Époque 1, Batch 800] perte: 0.182\n",
            "[Époque 2, Batch 200] perte: 0.140\n",
            "[Époque 2, Batch 400] perte: 0.113\n",
            "[Époque 2, Batch 600] perte: 0.102\n",
            "[Époque 2, Batch 800] perte: 0.103\n",
            "[Époque 3, Batch 200] perte: 0.084\n",
            "[Époque 3, Batch 400] perte: 0.087\n",
            "[Époque 3, Batch 600] perte: 0.075\n",
            "[Époque 3, Batch 800] perte: 0.076\n",
            "Entraînement terminé.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluer le modèle"
      ],
      "metadata": {
        "id": "uoULdkcjqz1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Mettre le modèle en mode évaluation\n",
        "model.eval()\n",
        "\n",
        "# Pas besoin de calculer les gradients pendant l'évaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "\n",
        "        # Obtenir les prédictions du modèle\n",
        "        outputs = model(images)\n",
        "\n",
        "        # torch.max renvoie (valeur_max, index_max)\n",
        "        # L'index_max (dim=1) est notre prédiction de classe\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Mettre à jour le total\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Mettre à jour le nombre de prédictions correctes\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Afficher la précision finale\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Précision du modèle sur les 10000 images de test: {accuracy:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOveYJ46m4A_",
        "outputId": "466f936e-e79c-4d7c-d07f-0ed31ce54f20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Précision du modèle sur les 10000 images de test: 98.06 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test sur 1 image aléatoire"
      ],
      "metadata": {
        "id": "2d1r2mKmq_Oh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "b08bc22d",
        "outputId": "a68ac0d3-7ed1-44a2-85e4-c076c64322e9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mettre le modèle en mode évaluation\n",
        "model.eval()\n",
        "\n",
        "# Prendre un lot (batch) d'images et d'étiquettes du jeu de test\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Sélectionner une image aléatoire dans le lot\n",
        "index = np.random.randint(0, len(images))\n",
        "image = images[index]\n",
        "label = labels[index]\n",
        "\n",
        "# Redimensionner l'image pour l'affichage (supprimer la dimension du canal)\n",
        "image_to_show = image.squeeze().numpy()\n",
        "\n",
        "# Faire une prédiction avec le modèle\n",
        "# Ajouter une dimension de lot car le modèle attend un lot d'images (même si un seul)\n",
        "output = model(image.unsqueeze(0))\n",
        "\n",
        "# Obtenir la classe prédite\n",
        "_, predicted = torch.max(output.data, 1)\n",
        "\n",
        "# Afficher l'image et la prédiction\n",
        "plt.imshow(image_to_show, cmap='gray')\n",
        "plt.title(f\"Vraie étiquette: {label.item()}, Prédiction du modèle: {predicted.item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}